{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Виртуальная стажировка Shift + Enter по направлению Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Тренировка классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset massive (/home/sergey/.cache/huggingface/datasets/AmazonScience___massive/en-US/1.0.0/71d360eb7d7a18565ff8c10609cebf714fce3cc390e173ba5b02ffd48543cdc1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c06e34743d445519efc3e2d76040785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# загрузка датасета\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "df = load_dataset(\"AmazonScience/massive\", \"en-US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "        num_rows: 11514\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "        num_rows: 2033\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'locale', 'partition', 'scenario', 'intent', 'utt', 'annot_utt', 'worker_id', 'slot_method', 'judgments'],\n",
       "        num_rows: 2974\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'locale': 'en-US',\n",
       " 'partition': 'train',\n",
       " 'scenario': 16,\n",
       " 'intent': 48,\n",
       " 'utt': 'wake me up at nine am on friday',\n",
       " 'annot_utt': 'wake me up at [time : nine am] on [date : friday]',\n",
       " 'worker_id': '1',\n",
       " 'slot_method': {'slot': [], 'method': []},\n",
       " 'judgments': {'worker_id': [],\n",
       "  'intent_score': [],\n",
       "  'slots_score': [],\n",
       "  'grammar_score': [],\n",
       "  'spelling_score': [],\n",
       "  'language_identification': []}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# первая строчка из трейн датасета\n",
    "df[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификации интента нам нужны лишь тексты запросов. Выберем только колонки `intent` и `utt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 11514\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 2033\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 2974\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.select_columns(column_names=[\"intent\", \"utt\"]).rename_columns({\"intent\":\"label\", \"utt\":\"text\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взглянем подробнее на фичу `intent` из `train` сплита нашего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 48, 'text': 'wake me up at nine am on friday'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# первая строка из трейна\n",
    "\n",
    "df[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# уникальные значения интента\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.unique(df[\"train\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['datetime_query', 'iot_hue_lightchange', 'transport_ticket', 'takeaway_query', 'qa_stock', 'general_greet', 'recommendation_events', 'music_dislikeness', 'iot_wemo_off', 'cooking_recipe', 'qa_currency', 'transport_traffic', 'general_quirky', 'weather_query', 'audio_volume_up', 'email_addcontact', 'takeaway_order', 'email_querycontact', 'iot_hue_lightup', 'recommendation_locations', 'play_audiobook', 'lists_createoradd', 'news_query', 'alarm_query', 'iot_wemo_on', 'general_joke', 'qa_definition', 'social_query', 'music_settings', 'audio_volume_other', 'calendar_remove', 'iot_hue_lightdim', 'calendar_query', 'email_sendemail', 'iot_cleaning', 'audio_volume_down', 'play_radio', 'cooking_query', 'datetime_convert', 'qa_maths', 'iot_hue_lightoff', 'iot_hue_lighton', 'transport_query', 'music_likeness', 'email_query', 'play_music', 'audio_volume_mute', 'social_post', 'alarm_set', 'qa_factoid', 'calendar_set', 'play_game', 'alarm_remove', 'lists_remove', 'transport_taxi', 'recommendation_movies', 'iot_coffee', 'music_query', 'play_podcasts', 'lists_query'], id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# другое представление intent\n",
    "\n",
    "df[\"train\"].features[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime_query',\n",
       " 'iot_hue_lightchange',\n",
       " 'transport_ticket',\n",
       " 'takeaway_query',\n",
       " 'qa_stock',\n",
       " 'general_greet',\n",
       " 'recommendation_events',\n",
       " 'music_dislikeness',\n",
       " 'iot_wemo_off',\n",
       " 'cooking_recipe',\n",
       " 'qa_currency',\n",
       " 'transport_traffic',\n",
       " 'general_quirky',\n",
       " 'weather_query',\n",
       " 'audio_volume_up',\n",
       " 'email_addcontact',\n",
       " 'takeaway_order',\n",
       " 'email_querycontact',\n",
       " 'iot_hue_lightup',\n",
       " 'recommendation_locations',\n",
       " 'play_audiobook',\n",
       " 'lists_createoradd',\n",
       " 'news_query',\n",
       " 'alarm_query',\n",
       " 'iot_wemo_on',\n",
       " 'general_joke',\n",
       " 'qa_definition',\n",
       " 'social_query',\n",
       " 'music_settings',\n",
       " 'audio_volume_other',\n",
       " 'calendar_remove',\n",
       " 'iot_hue_lightdim',\n",
       " 'calendar_query',\n",
       " 'email_sendemail',\n",
       " 'iot_cleaning',\n",
       " 'audio_volume_down',\n",
       " 'play_radio',\n",
       " 'cooking_query',\n",
       " 'datetime_convert',\n",
       " 'qa_maths',\n",
       " 'iot_hue_lightoff',\n",
       " 'iot_hue_lighton',\n",
       " 'transport_query',\n",
       " 'music_likeness',\n",
       " 'email_query',\n",
       " 'play_music',\n",
       " 'audio_volume_mute',\n",
       " 'social_post',\n",
       " 'alarm_set',\n",
       " 'qa_factoid',\n",
       " 'calendar_set',\n",
       " 'play_game',\n",
       " 'alarm_remove',\n",
       " 'lists_remove',\n",
       " 'transport_taxi',\n",
       " 'recommendation_movies',\n",
       " 'iot_coffee',\n",
       " 'music_query',\n",
       " 'play_podcasts',\n",
       " 'lists_query']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# извлечем имена из структуры выше\n",
    "\n",
    "df[\"train\"].features[\"label\"].names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало понятно, что `intent` - это индексы из списка категорий.\n",
    "\n",
    "Теперь надо токенизировать датасет, чтобы модель поняла естественный язык"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем токенайзер с BERT (distilled)\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sergey/.cache/huggingface/datasets/AmazonScience___massive/en-US/1.0.0/71d360eb7d7a18565ff8c10609cebf714fce3cc390e173ba5b02ffd48543cdc1/cache-83b6b07a3394febc.arrow\n",
      "Loading cached processed dataset at /home/sergey/.cache/huggingface/datasets/AmazonScience___massive/en-US/1.0.0/71d360eb7d7a18565ff8c10609cebf714fce3cc390e173ba5b02ffd48543cdc1/cache-68d8601ed7a617eb.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a185e110a84db8b0c8c303696f9567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 11514\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2033\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2974\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# токенезируем все, что имеем\n",
    "\n",
    "\n",
    "def utt_tokenization(data):\n",
    "    return tokenizer(data[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_df = df.map(utt_tokenization, batched=True)\n",
    "tokenized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее загрузим методы оценки\n",
    "\n",
    "Используемые метрики:\n",
    "- accuracy - точность модели в целом\n",
    "- precision (micro) - точность в предсказании правильных значений\n",
    "- recall (micro) - доля нахождения правильных значений\n",
    "- roc_auc (micro) - среднее значение площадей под кривыми, показывающими зависимость между чувствительностью и специфичностью для каждого класса.\n",
    "\n",
    "Чем ближе эти метрики к 1, тем лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка метрик\n",
    "\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\", \"multilabel\")\n",
    "recall = evaluate.load(\"recall\", \"multilabel\")\n",
    "roc_auc = evaluate.load(\"roc_auc\", \"multilabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для вычисления метрик\n",
    "\n",
    "\n",
    "def compute_metrics(model_pred):\n",
    "    predictions, labels = model_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    scores = {\n",
    "        \"accuracy\":accuracy.compute(predictions=predictions, references=labels),\n",
    "        \"precision\":precision.compute(predictions=predictions, references=labels, average=\"micro\"),\n",
    "        \"recall\":recall.compute(predictions=predictions, references=labels, average=\"micro\"),\n",
    "        \"roc_auc\":roc_auc.compute(predictions=predictions, references=labels, average=\"micro\")\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь начинаем подготовку к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/sergey/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"datetime_query\",\n",
      "    \"1\": \"iot_hue_lightchange\",\n",
      "    \"2\": \"transport_ticket\",\n",
      "    \"3\": \"takeaway_query\",\n",
      "    \"4\": \"qa_stock\",\n",
      "    \"5\": \"general_greet\",\n",
      "    \"6\": \"recommendation_events\",\n",
      "    \"7\": \"music_dislikeness\",\n",
      "    \"8\": \"iot_wemo_off\",\n",
      "    \"9\": \"cooking_recipe\",\n",
      "    \"10\": \"qa_currency\",\n",
      "    \"11\": \"transport_traffic\",\n",
      "    \"12\": \"general_quirky\",\n",
      "    \"13\": \"weather_query\",\n",
      "    \"14\": \"audio_volume_up\",\n",
      "    \"15\": \"email_addcontact\",\n",
      "    \"16\": \"takeaway_order\",\n",
      "    \"17\": \"email_querycontact\",\n",
      "    \"18\": \"iot_hue_lightup\",\n",
      "    \"19\": \"recommendation_locations\",\n",
      "    \"20\": \"play_audiobook\",\n",
      "    \"21\": \"lists_createoradd\",\n",
      "    \"22\": \"news_query\",\n",
      "    \"23\": \"alarm_query\",\n",
      "    \"24\": \"iot_wemo_on\",\n",
      "    \"25\": \"general_joke\",\n",
      "    \"26\": \"qa_definition\",\n",
      "    \"27\": \"social_query\",\n",
      "    \"28\": \"music_settings\",\n",
      "    \"29\": \"audio_volume_other\",\n",
      "    \"30\": \"calendar_remove\",\n",
      "    \"31\": \"iot_hue_lightdim\",\n",
      "    \"32\": \"calendar_query\",\n",
      "    \"33\": \"email_sendemail\",\n",
      "    \"34\": \"iot_cleaning\",\n",
      "    \"35\": \"audio_volume_down\",\n",
      "    \"36\": \"play_radio\",\n",
      "    \"37\": \"cooking_query\",\n",
      "    \"38\": \"datetime_convert\",\n",
      "    \"39\": \"qa_maths\",\n",
      "    \"40\": \"iot_hue_lightoff\",\n",
      "    \"41\": \"iot_hue_lighton\",\n",
      "    \"42\": \"transport_query\",\n",
      "    \"43\": \"music_likeness\",\n",
      "    \"44\": \"email_query\",\n",
      "    \"45\": \"play_music\",\n",
      "    \"46\": \"audio_volume_mute\",\n",
      "    \"47\": \"social_post\",\n",
      "    \"48\": \"alarm_set\",\n",
      "    \"49\": \"qa_factoid\",\n",
      "    \"50\": \"calendar_set\",\n",
      "    \"51\": \"play_game\",\n",
      "    \"52\": \"alarm_remove\",\n",
      "    \"53\": \"lists_remove\",\n",
      "    \"54\": \"transport_taxi\",\n",
      "    \"55\": \"recommendation_movies\",\n",
      "    \"56\": \"iot_coffee\",\n",
      "    \"57\": \"music_query\",\n",
      "    \"58\": \"play_podcasts\",\n",
      "    \"59\": \"lists_query\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"alarm_query\": 23,\n",
      "    \"alarm_remove\": 52,\n",
      "    \"alarm_set\": 48,\n",
      "    \"audio_volume_down\": 35,\n",
      "    \"audio_volume_mute\": 46,\n",
      "    \"audio_volume_other\": 29,\n",
      "    \"audio_volume_up\": 14,\n",
      "    \"calendar_query\": 32,\n",
      "    \"calendar_remove\": 30,\n",
      "    \"calendar_set\": 50,\n",
      "    \"cooking_query\": 37,\n",
      "    \"cooking_recipe\": 9,\n",
      "    \"datetime_convert\": 38,\n",
      "    \"datetime_query\": 0,\n",
      "    \"email_addcontact\": 15,\n",
      "    \"email_query\": 44,\n",
      "    \"email_querycontact\": 17,\n",
      "    \"email_sendemail\": 33,\n",
      "    \"general_greet\": 5,\n",
      "    \"general_joke\": 25,\n",
      "    \"general_quirky\": 12,\n",
      "    \"iot_cleaning\": 34,\n",
      "    \"iot_coffee\": 56,\n",
      "    \"iot_hue_lightchange\": 1,\n",
      "    \"iot_hue_lightdim\": 31,\n",
      "    \"iot_hue_lightoff\": 40,\n",
      "    \"iot_hue_lighton\": 41,\n",
      "    \"iot_hue_lightup\": 18,\n",
      "    \"iot_wemo_off\": 8,\n",
      "    \"iot_wemo_on\": 24,\n",
      "    \"lists_createoradd\": 21,\n",
      "    \"lists_query\": 59,\n",
      "    \"lists_remove\": 53,\n",
      "    \"music_dislikeness\": 7,\n",
      "    \"music_likeness\": 43,\n",
      "    \"music_query\": 57,\n",
      "    \"music_settings\": 28,\n",
      "    \"news_query\": 22,\n",
      "    \"play_audiobook\": 20,\n",
      "    \"play_game\": 51,\n",
      "    \"play_music\": 45,\n",
      "    \"play_podcasts\": 58,\n",
      "    \"play_radio\": 36,\n",
      "    \"qa_currency\": 10,\n",
      "    \"qa_definition\": 26,\n",
      "    \"qa_factoid\": 49,\n",
      "    \"qa_maths\": 39,\n",
      "    \"qa_stock\": 4,\n",
      "    \"recommendation_events\": 6,\n",
      "    \"recommendation_locations\": 19,\n",
      "    \"recommendation_movies\": 55,\n",
      "    \"social_post\": 47,\n",
      "    \"social_query\": 27,\n",
      "    \"takeaway_order\": 16,\n",
      "    \"takeaway_query\": 3,\n",
      "    \"transport_query\": 42,\n",
      "    \"transport_taxi\": 54,\n",
      "    \"transport_ticket\": 2,\n",
      "    \"transport_traffic\": 11,\n",
      "    \"weather_query\": 13\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/sergey/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# словари для лейблов и их индексов в обе стороны, чтобы модель разобралась, что предсказывать\n",
    "label2id = {v: i for i, v in enumerate(df[\"train\"].features[\"label\"].names)}\n",
    "id2label = {i: v for i, v in enumerate(df[\"train\"].features[\"label\"].names)}\n",
    "\n",
    "# инициализация модели\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=len(df[\"train\"].features[\"label\"].names),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# аргументы для обучения\n",
    "training_args = TrainingArguments(output_dir=\"intent-class-model\")\n",
    "\n",
    "# объект учителя\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_df[\"train\"],\n",
    "    eval_dataset=tokenized_df[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начинаем обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/sergey/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 11514\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4320\n",
      "  Number of trainable parameters = 66999612\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de42bedb74f94869a2604879f3a5e37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to intent-class-model/checkpoint-500\n",
      "Configuration saved in intent-class-model/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1555, 'learning_rate': 4.4212962962962966e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in intent-class-model/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in intent-class-model/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in intent-class-model/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to intent-class-model/checkpoint-1000\n",
      "Configuration saved in intent-class-model/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8766, 'learning_rate': 3.8425925925925924e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in intent-class-model/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in intent-class-model/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in intent-class-model/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to intent-class-model/checkpoint-1500\n",
      "Configuration saved in intent-class-model/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6126, 'learning_rate': 3.263888888888889e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in intent-class-model/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in intent-class-model/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in intent-class-model/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to intent-class-model/checkpoint-2000\n",
      "Configuration saved in intent-class-model/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3425, 'learning_rate': 2.6851851851851855e-05, 'epoch': 1.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in intent-class-model/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in intent-class-model/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in intent-class-model/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to intent-class-model/checkpoint-2500\n",
      "Configuration saved in intent-class-model/checkpoint-2500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3586, 'learning_rate': 2.1064814814814816e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in intent-class-model/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in intent-class-model/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in intent-class-model/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to intent-class-model/checkpoint-3000\n",
      "Configuration saved in intent-class-model/checkpoint-3000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.297, 'learning_rate': 1.527777777777778e-05, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in intent-class-model/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in intent-class-model/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in intent-class-model/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to intent-class-model/checkpoint-3500\n",
      "Configuration saved in intent-class-model/checkpoint-3500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1467, 'learning_rate': 9.490740740740741e-06, 'epoch': 2.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in intent-class-model/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in intent-class-model/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in intent-class-model/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to intent-class-model/checkpoint-4000\n",
      "Configuration saved in intent-class-model/checkpoint-4000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1793, 'learning_rate': 3.7037037037037037e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in intent-class-model/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in intent-class-model/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in intent-class-model/checkpoint-4000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2174.4752, 'train_samples_per_second': 15.885, 'train_steps_per_second': 1.987, 'train_loss': 0.5884717985435769, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4320, training_loss=0.5884717985435769, metrics={'train_runtime': 2174.4752, 'train_samples_per_second': 15.885, 'train_steps_per_second': 1.987, 'train_loss': 0.5884717985435769, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2033\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d4894959ee4adfb4266177cb4ad78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'references': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None)},\nInput predictions: [40 31 31 ... 33 44 17],\nInput references: [40 31 31 ... 33 44 17]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mevaluate()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/trainer.py:2796\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2793\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2795\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2796\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   2797\u001b[0m     eval_dataloader,\n\u001b[1;32m   2798\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   2799\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2800\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2801\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2802\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   2803\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   2804\u001b[0m )\n\u001b[1;32m   2806\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   2807\u001b[0m output\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m   2808\u001b[0m     speed_metrics(\n\u001b[1;32m   2809\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2813\u001b[0m     )\n\u001b[1;32m   2814\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/trainer.py:3081\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3077\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3078\u001b[0m             EvalPrediction(predictions\u001b[39m=\u001b[39mall_preds, label_ids\u001b[39m=\u001b[39mall_labels, inputs\u001b[39m=\u001b[39mall_inputs)\n\u001b[1;32m   3079\u001b[0m         )\n\u001b[1;32m   3080\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3081\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics(EvalPrediction(predictions\u001b[39m=\u001b[39;49mall_preds, label_ids\u001b[39m=\u001b[39;49mall_labels))\n\u001b[1;32m   3082\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3083\u001b[0m     metrics \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32m/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb Cell 23\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(model_pred)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m predictions, labels \u001b[39m=\u001b[39m model_pred\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb#X46sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m scores \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m:accuracy\u001b[39m.\u001b[39mcompute(predictions\u001b[39m=\u001b[39mpredictions\u001b[39m.\u001b[39mflatten(), references\u001b[39m=\u001b[39mlabels\u001b[39m.\u001b[39mflatten()),\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb#X46sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m\"\u001b[39m:precision\u001b[39m.\u001b[39;49mcompute(predictions\u001b[39m=\u001b[39;49mpredictions\u001b[39m.\u001b[39;49mflatten(), references\u001b[39m=\u001b[39;49mlabels\u001b[39m.\u001b[39;49mflatten(), average\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmicro\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb#X46sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m\"\u001b[39m:recall\u001b[39m.\u001b[39mcompute(predictions\u001b[39m=\u001b[39mpredictions\u001b[39m.\u001b[39mflatten(), references\u001b[39m=\u001b[39mlabels\u001b[39m.\u001b[39mflatten(), average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb#X46sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mroc_auc\u001b[39m\u001b[39m\"\u001b[39m:roc_auc\u001b[39m.\u001b[39mcompute(predictions\u001b[39m=\u001b[39mpredictions\u001b[39m.\u001b[39mflatten(), references\u001b[39m=\u001b[39mlabels\u001b[39m.\u001b[39mflatten(), average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb#X46sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergey/Desktop/Coding/Python/shift_enter_ds/ds_intern.ipynb#X46sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/evaluate/module.py:432\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m compute_kwargs \u001b[39m=\u001b[39m {k: kwargs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m kwargs \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feature_names()}\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m--> 432\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_batch(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m    433\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finalize()\n\u001b[1;32m    435\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_file_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/evaluate/module.py:512\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    507\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredictions and/or references don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match the expected format.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected format: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselected_feature_format\u001b[39m \u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput predictions: \u001b[39m\u001b[39m{\u001b[39;00msummarize_if_long_list(predictions)\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput references: \u001b[39m\u001b[39m{\u001b[39;00msummarize_if_long_list(references)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m     )\n\u001b[0;32m--> 512\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(error_msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'references': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None)},\nInput predictions: [40 31 31 ... 33 44 17],\nInput references: [40 31 31 ... 33 44 17]"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "Что касается улучшения модели для учета out-of-scope запросов, есть две опции по обнаружению таких запросов:\n",
    "- добавить дополнительную модель поверх - бинарный классификатор - которая распознает, out-of-scope ли запрос или нет\n",
    "- вынести out-of-scope запросы в отдельный класс и использовать ту же модель\n",
    "\n",
    "Для обоих методов, конечно, потребуются дополнительные данные, помеченные out-of-scope меткой, причем довольно много:\n",
    "- неразборчивый текст/несвязный набор слов или букв\n",
    "- запросы, не имеющие отношения к какой-либо теме (пустой диалог, например)\n",
    "- запросы с неизвестным пока еще интентом\n",
    "\n",
    "\n",
    "Насчет пользователей. Можно просто оповестить их сообщением \"не могу удовлетворить ваш запрос\" и прочие вариации. Однако есть идея поинтереснее: для улучшения пользовательского экспириенса, можно разбить out-of-scope класс на подклассы (по типу перечисления вариантов данных выше) и, исходя из подкласса, выдавать реакцию. Если смысл запроса не понятен вообще, то можно выдать просьбу о повторе запроса. Если смысл понятен, но не несет какого-либо интента, то можно продумать различные фразы с предложением какого-либо другого интента. Например: \"не понимаю, о чем идет речь, но могу поставить будильник на завтра, чтобы вы не проспали\". Если запрос неизвестен, то можно сделать так: извиниться и отправить специальную форму, где пользователь сам поставит метку своему запросу. Эта форма потом отправляется в data science отдел, где собираются дополнительные данные, и учитывается в последующем дообучении\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
